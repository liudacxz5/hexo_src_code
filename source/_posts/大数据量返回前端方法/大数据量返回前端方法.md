## 大数据量返回前端方法
在处理数千条数据时，直接将全部数据通过 JSON 返回前端可能导致 **性能问题**（如响应体积过大、传输延迟、前端渲染卡顿）。以下是更优化的解决方案及具体实现方法：

---

### **1. 分页返回（Pagination）**
适用于前端需要逐步加载或展示数据的场景（如表格分页）。

#### **实现步骤（FastAPI 示例）**
```python
from fastapi import APIRouter, Query
import pandas as pd

router = APIRouter()

@router.get("/data")
async def get_paginated_data(
    page: int = Query(1, ge=1),  # 当前页码（从1开始）
    page_size: int = Query(100, ge=1)  # 每页数据量
):
    # 从数据库或缓存加载完整数据（假设 df 是处理后的 DataFrame）
    df = pd.read_csv("large_data.csv")
    
    # 计算分页切片
    total = len(df)
    start = (page - 1) * page_size
    end = start + page_size
    paginated_df = df.iloc[start:end]
    
    # 返回分页结果和元数据
    return {
        "data": paginated_df.to_dict(orient="records"),
        "pagination": {
            "total": total,
            "page": page,
            "page_size": page_size,
            "total_pages": (total + page_size - 1) // page_size
        }
    }
```

#### **优点**
- 减少单次响应体积，提升传输速度。
- 避免前端一次性渲染大量数据。

---

### **2. 流式传输（Streaming Response）**
适用于需要**实时推送**或**逐批处理**的超大数据集。

#### **实现步骤（FastAPI + 生成器流式返回）**
```python
from fastapi import Response
from fastapi.responses import StreamingResponse
import pandas as pd

@router.get("/stream-data")
async def stream_data():
    df = pd.read_csv("large_data.csv")
    
    # 定义生成器逐行输出数据
    def generate():
        yield df.columns.to_json() + "\n"  # 先发送表头
        for _, row in df.iterrows():
            yield row.to_json() + "\n"  # 逐行发送数据
    
    return StreamingResponse(
        generate(),
        media_type="application/x-ndjson"  # 流式 JSON 格式
    )
```

#### **前端处理**
```javascript
// 使用 Fetch API 处理流式数据
fetch("/stream-data")
  .then(response => {
    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    
    function readChunk() {
      return reader.read().then(({ value, done }) => {
        if (done) return;
        const chunk = decoder.decode(value);
        console.log("Received:", JSON.parse(chunk));
        readChunk();
      });
    }
    readChunk();
  });
```

---

### **3. 压缩响应（Compression）**
若必须返回完整数据，可通过 **Gzip/Brotli 压缩**减少传输体积。

#### **FastAPI 自动压缩配置**
```python
# 启用压缩中间件（需安装 uvicorn 并启用压缩）
from fastapi.middleware.gzip import GZipMiddleware

app = FastAPI()
app.add_middleware(GZipMiddleware, minimum_size=500)  # 大于 500B 的数据自动压缩

@router.get("/full-data")
async def get_full_data():
    df = pd.read_csv("large_data.csv")
    return df.to_dict(orient="records")
```

#### **优点**
- 无需修改前端代码，透明压缩。
- 减少 60%~90% 的传输体积。

---

### **4. 返回文件下载链接**
适用于前端需要**导出数据**的场景（如 CSV、Excel 文件）。

#### **实现步骤（FastAPI 返回文件）**
```python
from fastapi.responses import FileResponse

@router.get("/download-csv")
async def download_csv():
    df = pd.read_csv("large_data.csv")
    csv_path = "temp_export.csv"
    df.to_csv(csv_path, index=False)
    return FileResponse(
        csv_path,
        filename="data_export.csv",
        media_type="text/csv"
    )
```

#### **前端调用**
```html
<a href="/download-csv" download>下载 CSV 文件</a>
```

---

### **5. 使用二进制格式（如 Parquet）**
适合对传输效率要求极高的场景（如数据科学协作）。

#### **实现步骤**
```python
import pyarrow.parquet as pq
from fastapi.responses import Response

@router.get("/binary-data")
async def get_binary_data():
    df = pd.read_csv("large_data.csv")
    buffer = BytesIO()
    df.to_parquet(buffer, engine="pyarrow")
    buffer.seek(0)
    return Response(
        content=buffer.read(),
        media_type="application/octet-stream",
        headers={"Content-Disposition": "attachment; filename=data.parquet"}
    )
```

#### **优点**
- Parquet 文件比 JSON/CSV 小 50%~80%。
- 支持列式存储和高效压缩。

---

### **方案对比**
| **方案**       | 传输体积 | 前端复杂度 | 适用场景                     |
|----------------|----------|------------|----------------------------|
| 分页           | 小       | 低         | 表格展示、交互式查询         |
| 流式传输       | 中       | 高         | 实时监控、大数据逐批处理     |
| 压缩 JSON      | 中       | 低         | 必须返回完整数据的 API       |
| 文件下载       | 大       | 低         | 数据导出、离线分析           |
| 二进制格式     | 小       | 高         | 数据科学、高性能传输         |

---

### **最佳实践建议**
1. **优先分页**：除非明确需要完整数据，否则默认使用分页。
2. **按需选择格式**：
   - 交互式 Web 应用 → **分页 JSON**
   - 数据导出 → **CSV/Excel 文件**
   - 科学计算 → **Parquet/二进制**
3. **监控性能**：使用 APM 工具（如 Prometheus）跟踪 API 响应时间和数据体积。